{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score)\n",
    "from utils.data import *\n",
    "from utils.deep_learning import *\n",
    "from utils.measuring_performance import *\n",
    "from utils.misc import *\n",
    "sys.path.append('../Fork/DeepCTR')\n",
    "from deepctr.inputs import DenseFeat, SparseFeat, get_feature_names\n",
    "from deepctr.inputs import input_from_feature_columns, get_linear_logit, build_input_features, combined_dnn_input, DEFAULT_GROUP_NAME\n",
    "from deepctr.layers.core import PredictionLayer, DNN\n",
    "from deepctr.layers.interaction import FM\n",
    "from deepctr.layers.utils import concat_func, add_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.abspath('../../Data/display_advertising_challenge/processed')\n",
    "MODEL_DIR = os.path.abspath('models')\n",
    "USE_TFRECORD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_type = 'train+valid'\n",
    "test_dataset_type = 'test'\n",
    "model_type = 'deepfm'\n",
    "model_path = os.path.join(MODEL_DIR, '_'.join([model_type, 'model', train_dataset_type]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name, num_feature_names, cat_feature_names, n_categories = load_pickle(\n",
    "    os.path.join(DATA_DIR, '_'.join([train_dataset_type, 'metadata.pkl'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TFRECORD:\n",
    "    train_dataset_path = os.path.join(DATA_DIR, '_'.join(['dataset', train_dataset_type]) + '.tfrecord')\n",
    "    test_dataset_path = os.path.join(DATA_DIR, '_'.join(['dataset', test_dataset_type]) + '.tfrecord')\n",
    "    \n",
    "    shuffle_buffer_size = 2 ** 20\n",
    "    train_dataset = extract_dataset(train_dataset_path, compression_type='GZIP', \n",
    "                                    shuffle_buffer_size=shuffle_buffer_size, is_training=True)\n",
    "    test_dataset = extract_dataset(test_dataset_path, compression_type='GZIP', \n",
    "                                    shuffle_buffer_size=shuffle_buffer_size, is_training=True)\n",
    "    \n",
    "    n, m = 36672494, 9168123\n",
    "    # n = get_n_examples(train_dataset)\n",
    "    # m = get_n_examples(test_dataset)\n",
    "    \n",
    "else:\n",
    "    df_y_train = pd.read_pickle(os.path.join(DATA_DIR, '_'.join(['df', 'y', train_dataset_type]) + '.pkl'))\n",
    "    df_X_train = pd.read_pickle(os.path.join(DATA_DIR, '_'.join(['df', 'X', train_dataset_type]) + '.pkl'))\n",
    "    df_y_test = pd.read_pickle(os.path.join(DATA_DIR, '_'.join(['df', 'y', test_dataset_type]) + '.pkl'))\n",
    "    df_X_test = pd.read_pickle(os.path.join(DATA_DIR, '_'.join(['df', 'X', test_dataset_type]) + '.pkl'))\n",
    "\n",
    "    train_model_input = {column: df_X_train[column].values for column in df_X_train.columns}\n",
    "    test_model_input = {column: df_X_test[column].values for column in df_X_test.columns}\n",
    "    \n",
    "    n = df_y_train.shape[0]\n",
    "    m = df_y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 4\n",
    "num_features = [DenseFeat(feature, 1) for feature in num_feature_names]\n",
    "cat_features = [SparseFeat(feature, vocabulary_size=n_categories[feature], \n",
    "                           embedding_dim=embedding_dim, use_hash=False) for feature in cat_feature_names]\n",
    "linear_features = num_features + cat_features\n",
    "dnn_features = num_features + cat_features\n",
    "all_feature_names = get_feature_names(num_features + cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = build_input_features(\n",
    "    linear_features + dnn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_list = list(features.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('I1', <tf.Tensor 'I1_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I2', <tf.Tensor 'I2_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I3', <tf.Tensor 'I3_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I4', <tf.Tensor 'I4_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I5', <tf.Tensor 'I5_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I6', <tf.Tensor 'I6_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I7', <tf.Tensor 'I7_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I8', <tf.Tensor 'I8_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I9', <tf.Tensor 'I9_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I10', <tf.Tensor 'I10_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I11', <tf.Tensor 'I11_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I12', <tf.Tensor 'I12_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('I13', <tf.Tensor 'I13_2:0' shape=(None, 1) dtype=float32>),\n",
       "             ('C1', <tf.Tensor 'C1_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C2', <tf.Tensor 'C2_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C3', <tf.Tensor 'C3_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C4', <tf.Tensor 'C4_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C5', <tf.Tensor 'C5_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C6', <tf.Tensor 'C6_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C7', <tf.Tensor 'C7_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C8', <tf.Tensor 'C8_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C9', <tf.Tensor 'C9_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C10', <tf.Tensor 'C10_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C11', <tf.Tensor 'C11_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C12', <tf.Tensor 'C12_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C13', <tf.Tensor 'C13_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C14', <tf.Tensor 'C14_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C15', <tf.Tensor 'C15_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C16', <tf.Tensor 'C16_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C17', <tf.Tensor 'C17_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C18', <tf.Tensor 'C18_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C19', <tf.Tensor 'C19_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C20', <tf.Tensor 'C20_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C21', <tf.Tensor 'C21_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C22', <tf.Tensor 'C22_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C23', <tf.Tensor 'C23_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C24', <tf.Tensor 'C24_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C25', <tf.Tensor 'C25_2:0' shape=(None, 1) dtype=int32>),\n",
       "             ('C26', <tf.Tensor 'C26_2:0' shape=(None, 1) dtype=int32>)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(linear_features, dnn_features, task='binary')\n",
    "if len(get_available_gpus()) > 1:\n",
    "    model = tf.keras.utils.multi_gpu_model(model, gpus=n_gpus)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=1, mode='max'),\n",
    "             tf.keras.callbacks.ModelCheckpoint(\n",
    "                 filepath=model_path + '.h5', monitor='val_auc', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 2 ** 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TFRECORD:\n",
    "    steps_per_epoch = n // batch_size\n",
    "    validation_steps = m // batch_size\n",
    "    \n",
    "    train_dataset = transform_dataset(train_dataset, num_feature_names, cat_feature_names, target_name)\n",
    "    test_dataset = transform_dataset(test_dataset, num_feature_names, cat_feature_names, target_name)\n",
    "    \n",
    "    train_generator = load_dataset(train_dataset, batch_size=batch_size, is_training=False)\n",
    "    valid_generator = load_dataset(test_dataset, batch_size=batch_size, is_training=False)\n",
    "        \n",
    "    else:\n",
    "        history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, \n",
    "                                      verbose=True, validation_data=valid_generator, \n",
    "                                      validation_steps=validation_steps, callbacks=callbacks)\n",
    "    \n",
    "else:\n",
    "    history = model.fit(train_model_input, df_y_train.values, batch_size=batch_size, epochs=epochs, \n",
    "                        verbose=True, validation_data=(test_model_input, df_y_test.values), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path + '.h5')\n",
    "dump_pickle(model_path + '_history.pkl', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path + '.h5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TFRECORD:\n",
    "    test_dataset = extract_dataset(test_dataset_path, compression_type='GZIP', \n",
    "                                   shuffle_buffer_size=shuffle_buffer_size, is_training=False)\n",
    "    test_dataset = transform_dataset(test_dataset, num_feature_names, cat_feature_names, target_name) \n",
    "    y_true = get_target(test_dataset)\n",
    "    \n",
    "    test_generator = load_dataset(test_dataset, batch_size=m, is_training=False)\n",
    "    y_score = model.predict_generator(test_generator).ravel()\n",
    "    \n",
    "else:\n",
    "    y_true = df_y_test.values\n",
    "    y_score = model.predict(test_model_input).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = y_true.mean()\n",
    "y_pred = get_y_pred(y_score, threshold=ctr)\n",
    "\n",
    "norm_entropy = get_norm_entropy(y_true, y_score)\n",
    "calibration = y_score.mean() / ctr\n",
    "accuracy, precision, recall, f1 = accuracy_score(y_true, y_pred), precision_score(y_true, y_pred), \\\n",
    "    recall_score(y_true, y_pred), f1_score(y_true, y_pred)\n",
    "\n",
    "confusion_matrix = plot_confusion_matrix(y_true, y_pred)\n",
    "auroc = plot_roc_curve(y_true, y_score)\n",
    "auprc = plot_pr_curve(y_true, y_score)\n",
    "_ = plot_lift_curve(y_true, y_score)\n",
    "_ = plot_class_density(y_true, y_score, threshold=ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(os.path.join(MODEL_DIR, '_'.join([model_type, 'metric', train_dataset_type]) + '.pkl'), \n",
    "            (norm_entropy, calibration, accuracy, precision, recall, f1, confusion_matrix, auroc, auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_type = 'quiz'\n",
    "score_path = os.path.join(MODEL_DIR, '_'.join([model_type, 'score', test_dataset_type]) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TFRECORD:\n",
    "    test_dataset_path = os.path.join(DATA_DIR, '_'.join([model_type, 'dataset', test_dataset_type]) + '.tfrecord')\n",
    "    test_dataset = extract_dataset(test_dataset_path, compression_type='GZIP', \n",
    "                                    shuffle_buffer_size=shuffle_buffer_size, is_training=False)\n",
    "    \n",
    "    m = 6042135 \n",
    "    # m = get_n_examples(test_dataset)\n",
    "    \n",
    "    test_dataset = transform_dataset(test_dataset, num_feature_names, cat_feature_names, target_name) \n",
    "    test_generator = load_dataset(test_dataset, batch_size=m, is_training=False)\n",
    "    y_score = model.predict_generator(test_generator).ravel()\n",
    "    \n",
    "else:\n",
    "    df_X_test = pd.read_pickle(os.path.join(DATA_DIR, '_'.join(['df', 'X', test_dataset_type]) + '.pkl'))\n",
    "    test_model_input = {column: df_X_test[column].values for column in df_X_test.columns}\n",
    "    y_score = model.predict(test_model_input).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(score_path, y_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
