{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score)\n",
    "from tensorflow.python.client import device_lib\n",
    "from utils.data import *\n",
    "from utils.measuring_performance import *\n",
    "from utils.misc import *\n",
    "sys.path.append('../Fork/DeepCTR')\n",
    "from deepctr.inputs import DenseFeat, SparseFeat, get_feature_names\n",
    "from deepctr.layers import custom_objects\n",
    "from deepctr.models import DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_rows_of_dataset(dataset):\n",
    "    n_rows = 0\n",
    "    for _ in dataset.take(-1):\n",
    "        n_rows += 1\n",
    "    return n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_feature_names(num_feature_names, cat_feature_names, target_name=None):\n",
    "    features = dict()\n",
    "    features[target_name] = tf.io.FixedLenFeature([], tf.int64)\n",
    "    for feature in num_feature_names:\n",
    "        features[feature] = tf.io.FixedLenFeature([], tf.float32)\n",
    "    for feature in cat_feature_names:\n",
    "        features[feature] = tf.io.FixedLenFeature([], tf.int64)\n",
    "\n",
    "    def _from_tfrecord(serialized):\n",
    "        example = tf.io.parse_single_example(serialized=serialized, features=features)\n",
    "        if target_name is not None:\n",
    "            label = example.pop(target_name)\n",
    "            return example, label\n",
    "        else:\n",
    "            return example\n",
    "    return _from_tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.abspath('../../Data/display_advertising_challenge/processed')\n",
    "MODEL_DIR = os.path.abspath('models')\n",
    "LOG_DIR = os.path.abspath('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_type = 'train+valid'\n",
    "test_dataset_type = 'test'\n",
    "model_type = 'deepfm'\n",
    "\n",
    "train_dataset_path = os.path.join(DATA_DIR, '_'.join(['dataset', train_dataset_type]) + '.tfrecord')\n",
    "test_dataset_path = os.path.join(DATA_DIR, '_'.join(['dataset', test_dataset_type]) + '.tfrecord')\n",
    "model_path = os.path.join(MODEL_DIR, '_'.join([model_type, 'model', train_dataset_type]) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name, num_feature_names, cat_feature_names, n_categories = load_pickle(\n",
    "    os.path.join(DATA_DIR, '_'.join([train_dataset_type, 'metadata.pkl'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_tfrecord = set_feature_names(num_feature_names, cat_feature_names, target_name)\n",
    "train_dataset = tf.data.TFRecordDataset(\n",
    "    filenames=train_dataset_path, compression_type='GZIP').map(from_tfrecord)\n",
    "test_dataset = tf.data.TFRecordDataset(\n",
    "    filenames=test_dataset_path, compression_type='GZIP').map(from_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 36672494 \n",
    "# n = get_n_rows_of_dataset(train_dataset)\n",
    "y_true = pd.read_pickle(os.path.join(DATA_DIR, '_'.join(['df', 'y', test_dataset_type]) + '.pkl')).values\n",
    "# y_true = np.array([y.numpy() for x, y in test_dataset.take(-1)])\n",
    "m = y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [DenseFeat(feature, 1) for feature in num_feature_names]\n",
    "cat_features = [SparseFeat(feature, vocabulary_size=n_categories[feature], \n",
    "                           embedding_dim=4, use_hash=False) for feature in cat_feature_names]\n",
    "linear_features = num_features + cat_features\n",
    "dnn_features = num_features + cat_features\n",
    "all_feature_names = get_feature_names(num_features + cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(linear_features, dnn_features, task='binary')\n",
    "if len(get_available_gpus()) >= 2:\n",
    "    model = tf.keras.utils.multi_gpu_model(model, gpus=n_gpus)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1),\n",
    "             tf.keras.callbacks.ModelCheckpoint(filepath=model_path, monitor='val_loss', save_best_only=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1, embeddings_freq=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 128\n",
    "shuffle_buffer_size = 12800\n",
    "\n",
    "generator = train_dataset.batch(batch_size).shuffle(shuffle_buffer_size, seed=42).repeat()\n",
    "validation_data = test_dataset.batch(batch_size).shuffle(shuffle_buffer_size, seed=42).repeat()\n",
    "\n",
    "steps_per_epoch = n // batch_size\n",
    "validation_steps = m // batch_size\n",
    "\n",
    "history = model.fit_generator(generator, steps_per_epoch=steps_per_epoch, epochs=n_epochs, verbose=True,\n",
    "                              validation_data=validation_data, validation_steps=validation_steps, \n",
    "                              callbacks=callbacks)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = test_dataset.map(lambda x, y: x).batch(m)\n",
    "y_score = model.predict_generator(generator).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = y_true.mean()\n",
    "y_pred = get_y_pred(y_score, threshold=ctr)\n",
    "\n",
    "norm_entropy = get_norm_entropy(y_true, y_score)\n",
    "calibration = y_score.mean() / ctr\n",
    "accuracy, precision, recall, f1 = accuracy_score(y_true, y_pred), precision_score(y_true, y_pred), \\\n",
    "    recall_score(y_true, y_pred), f1_score(y_true, y_pred)\n",
    "\n",
    "confusion_matrix = plot_confusion_matrix(y_true, y_pred)\n",
    "auroc = plot_roc_curve(y_true, y_score)\n",
    "auprc = plot_pr_curve(y_true, y_score)\n",
    "_ = plot_lift_curve(y_true, y_score)\n",
    "_ = plot_class_density(y_true, y_score, threshold=ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(os.path.join(MODEL_DIR, '_'.join([model_type, 'metric', train_dataset_type]) + '.pkl'), \n",
    "            (norm_entropy, calibration, accuracy, precision, recall, f1, confusion_matrix, auroc, auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_type = 'quiz'\n",
    "test_dataset_path = os.path.join(DATA_DIR, '_'.join([model_type, 'dataset', test_dataset_type]) + '.tfrecord')\n",
    "score_path = os.path.join(MODEL_DIR, '_'.join([model_type, 'score', test_dataset_type]) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_tfrecord = set_feature_names(num_feature_names, cat_feature_names)\n",
    "test_dataset = tf.data.TFRecordDataset(\n",
    "    filenames=test_dataset_path, compression_type='GZIP').map(from_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 6042135 \n",
    "# m = get_n_rows_of_dataset(test_dataset)\n",
    "generator = test_dataset.batch(m)\n",
    "y_score = model.predict_generator(generator).ravel()\n",
    "dump_pickle(score_path, y_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
